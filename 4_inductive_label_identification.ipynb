{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import bigrams\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('3_SML_data_final.csv')\n",
    "df.drop(labels = ['Unnamed: 0'], axis = 1, inplace = True)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text_clean\"].to_list()\n",
    "texts =[x.lower() for x in texts]\n",
    "pattern = re.compile(r\"climat[e]*|heat[ing]*|warm[ing]*|greenhous[e]\", re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bigrams = []\n",
    "\n",
    "for article in texts:\n",
    "    matches = re.findall(pattern, article)\n",
    "    words = word_tokenize(article)\n",
    "    target_bigrams = list(bigrams(words))\n",
    "    target_bigrams = [(word1, word2) for word1, word2 in target_bigrams if word1 in matches or word2 in matches]\n",
    "    all_bigrams.extend(target_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_counts = Counter(all_bigrams)\n",
    "filtered_list = [element for element, count in element_counts.items() if count >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607bc422",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0499753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence(text, query):\n",
    "    #import re\n",
    "    #text = str(text).lower()\n",
    "    sentences = \"\"\n",
    "    #query = str(query).lower()\n",
    "    \n",
    "    for sentence in text.split('.'):\n",
    "        newsen = re.sub(r'[^\\w\\s.]', ' ', sentence)\n",
    "        if query in newsen:\n",
    "            sentences = sentences+'.'+sentence\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3160a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"changing climate\", 'climate risk', 'climate problem', 'severe climate', 'climate extremes', \n",
    "         'extreme climate', 'dangerous climate', 'climate challenge', 'climate risks', 'climate wars',\n",
    "        'climate issue', 'climate concerns', 'climate changes', 'catastrophic climate', 'climate hazards',\n",
    "        'warmer climate', 'climate disasters', 'abrupt climate', 'climate damage', 'catastrophic warming',\n",
    "        'planetary warming', 'atmospheric warming', 'climate warms', 'greenhouse warming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict = {}\n",
    "\n",
    "for name in names:\n",
    "    sentences_dict[name] = []\n",
    "    for article in texts:\n",
    "        extracted_sen = extract_sentence(article, name)\n",
    "        if len(extracted_sen) != 0:\n",
    "            sentences_dict[name].append(extracted_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('4_inductive_label_identification_inductive_identification_sentences.pkl', 'wb') as fp:\n",
    "    pickle.dump(sentences_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b49589",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dict[\"climate problem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences_dict[\"greenhouse warming\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed761760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
