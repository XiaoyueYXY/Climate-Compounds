{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd74ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import dateparser\n",
    "import re\n",
    "from striprtf.striprtf import rtf_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "89fb2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(file):\n",
    " \n",
    "    # Open a TXT file. Store all articles in a list. Each article is an item\n",
    "    # of the list. Split articles based on the location of such string as\n",
    "    # 'Document PRN0000020080617e46h00461'\n",
    " \n",
    "    articles = []\n",
    "    i = 1\n",
    "    filename = []\n",
    "    with open(file, 'r') as infile:\n",
    "        data = infile.read()\n",
    "    start = re.search(r' \\n', data).start()\n",
    "    for m in re.finditer(r'Dokument [a-zA-Z0-9]{25}\\n', data):\n",
    "        end = m.end()\n",
    "        a = data[start:end].strip()\n",
    "        a = '\\n   ' + a\n",
    "        name = file + f\"_{i}\"\n",
    "        articles.append(a)\n",
    "        filename.append(name)\n",
    "        start = end\n",
    "        i+=1\n",
    "    \n",
    "    return articles, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4bc0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findbetween(text, st, en):\n",
    "\n",
    "    start = re.search(st, text).end()\n",
    "    end = re.search(en, text).start()\n",
    "    a = text[start:end].strip()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3723d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findtime(text, st, en):\n",
    "\n",
    "    start = re.search(st, text).start()\n",
    "    end = re.search(en, text).end()\n",
    "    a = text[start:end].strip()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ccacf",
   "metadata": {},
   "source": [
    "### For Factiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1591409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/Sunday Times/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Sunday Times\\n\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "Sunday_Times = pd.DataFrame()\n",
    "Sunday_Times[\"filename\"] = names\n",
    "Sunday_Times[\"text_original\"] = news\n",
    "Sunday_Times[\"date\"] = time\n",
    "Sunday_Times[\"year\"] = Sunday_Times[\"date\"].dt.year\n",
    "Sunday_Times[\"month\"] = Sunday_Times[\"date\"].dt.month\n",
    "Sunday_Times[\"outlet\"] = \"Sunday Times\"\n",
    "Sunday_Times[\"country\"] = \"South Africa\"\n",
    "Sunday_Times[\"text_clean\"] = clean_text\n",
    "Sunday_Times[\"South\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b04a3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Globe & Mail/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Globe and Mail\\n\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "Globe_Mail = pd.DataFrame()\n",
    "Globe_Mail[\"filename\"] = names\n",
    "Globe_Mail[\"text_original\"] = news\n",
    "Globe_Mail[\"date\"] = time\n",
    "Globe_Mail[\"year\"] = Globe_Mail[\"date\"].dt.year\n",
    "Globe_Mail[\"month\"] = Globe_Mail[\"date\"].dt.month\n",
    "Globe_Mail[\"outlet\"] = \"GlobeMail\"\n",
    "Globe_Mail[\"country\"] = \"Canada\"\n",
    "Globe_Mail[\"text_clean\"] = clean_text\n",
    "Globe_Mail[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "551f8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Hindu/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Hindu\\n\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "Hindu = pd.DataFrame()\n",
    "Hindu[\"filename\"] = names\n",
    "Hindu[\"text_original\"] = news\n",
    "Hindu[\"date\"] = time\n",
    "Hindu[\"year\"] = Hindu[\"date\"].dt.year\n",
    "Hindu[\"month\"] = Hindu[\"date\"].dt.month\n",
    "Hindu[\"outlet\"] = \"Hindu\"\n",
    "Hindu[\"country\"] = \"India\"\n",
    "Hindu[\"text_clean\"] = clean_text\n",
    "Hindu[\"South\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d3501abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Nation/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Nation.*\\nTHENAT\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "The_Nation = pd.DataFrame()\n",
    "The_Nation[\"filename\"] = names\n",
    "The_Nation[\"text_original\"] = news\n",
    "The_Nation[\"date\"] = time\n",
    "The_Nation[\"year\"] = The_Nation[\"date\"].dt.year\n",
    "The_Nation[\"month\"] = The_Nation[\"date\"].dt.month\n",
    "The_Nation[\"outlet\"] = \"The Nation\"\n",
    "The_Nation[\"country\"] = \"Thailand\"\n",
    "The_Nation[\"text_clean\"] = clean_text\n",
    "The_Nation[\"South\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "45a35a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The New Zealand Herald/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\n.*New Zealand Herald\\n\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "NZ_Herald = pd.DataFrame()\n",
    "NZ_Herald[\"filename\"] = names\n",
    "NZ_Herald[\"text_original\"] = news\n",
    "NZ_Herald[\"date\"] = time\n",
    "NZ_Herald[\"year\"] = NZ_Herald[\"date\"].dt.year\n",
    "NZ_Herald[\"month\"] = NZ_Herald[\"date\"].dt.month\n",
    "NZ_Herald[\"outlet\"] = \"The New Zealand Herald\"\n",
    "NZ_Herald[\"country\"] = \"New Zealand\"\n",
    "NZ_Herald[\"text_clean\"] = clean_text\n",
    "NZ_Herald[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "926cac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Star/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Star\\nTHESTR\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "Star = pd.DataFrame()\n",
    "Star[\"filename\"] = names\n",
    "Star[\"text_original\"] = news\n",
    "Star[\"date\"] = time\n",
    "Star[\"year\"] = Star[\"date\"].dt.year\n",
    "Star[\"month\"] = Star[\"date\"].dt.month\n",
    "Star[\"outlet\"] = \"The Star\"\n",
    "Star[\"country\"] = \"South Africa\"\n",
    "Star[\"text_clean\"] = clean_text\n",
    "Star[\"South\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "28d44803",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Times/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Times\\nT\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "Times = pd.DataFrame()\n",
    "Times[\"filename\"] = names\n",
    "Times[\"text_original\"] = news\n",
    "Times[\"date\"] = time\n",
    "Times[\"year\"] = Times[\"date\"].dt.year\n",
    "Times[\"month\"] = Times[\"date\"].dt.month\n",
    "Times[\"outlet\"] = \"The Times\"\n",
    "Times[\"country\"] = \"UK\"\n",
    "Times[\"text_clean\"] = clean_text\n",
    "Times[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "33c4af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Washington Post/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Washington Post\\nWP\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "WPost = pd.DataFrame()\n",
    "WPost[\"filename\"] = names\n",
    "WPost[\"text_original\"] = news\n",
    "WPost[\"date\"] = time\n",
    "WPost[\"year\"] = WPost[\"date\"].dt.year\n",
    "WPost[\"month\"] = WPost[\"date\"].dt.month\n",
    "WPost[\"outlet\"] = \"The Washington Post\"\n",
    "WPost[\"country\"] = \"USA\"\n",
    "WPost[\"text_clean\"] = clean_text\n",
    "WPost[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ce18e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/Times of India/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Times of India\\nTOI\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "Times_IN = pd.DataFrame()\n",
    "Times_IN[\"filename\"] = names\n",
    "Times_IN[\"text_original\"] = news\n",
    "Times_IN[\"date\"] = time\n",
    "Times_IN[\"year\"] = Times_IN[\"date\"].dt.year\n",
    "Times_IN[\"month\"] = Times_IN[\"date\"].dt.month\n",
    "Times_IN[\"outlet\"] = \"Times of India\"\n",
    "Times_IN[\"country\"] = \"India\"\n",
    "Times_IN[\"text_clean\"] = clean_text\n",
    "Times_IN[\"South\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "582f1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/Toronto Star/**/*.txt\", recursive = True):  \n",
    "    articles, name = parser(files)\n",
    "    news.extend(articles)\n",
    "    names.extend(name)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"Wöter\\n\", \"\\nThe Toronto Star\\nTOR\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "\n",
    "TO_Star = pd.DataFrame()\n",
    "TO_Star[\"filename\"] = names\n",
    "TO_Star[\"text_original\"] = news\n",
    "TO_Star[\"date\"] = time\n",
    "TO_Star[\"year\"] = TO_Star[\"date\"].dt.year\n",
    "TO_Star[\"month\"] = TO_Star[\"date\"].dt.month\n",
    "TO_Star[\"outlet\"] = \"Toronto Star\"\n",
    "TO_Star[\"country\"] = \"Canada\"\n",
    "TO_Star[\"text_clean\"] = clean_text\n",
    "TO_Star[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a49b00",
   "metadata": {},
   "source": [
    "### For Nexis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "17f72690",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/Bangkok Post/**/*.rtf\", recursive = True):\n",
    "    with open(files, \"r\") as fi:\n",
    "        rtf = fi.read()    \n",
    "        text = rtf_to_text(rtf)\n",
    "        news.append(text)\n",
    "        names.append(files)\n",
    "    \n",
    "for n in news:\n",
    "    results = findbetween(n, \"\\nThe Bangkok Post.*\\n\", \"\\n\\n\\nCopyright\")\n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "    \n",
    "Bangkok_PO = pd.DataFrame()\n",
    "Bangkok_PO[\"filename\"] = names\n",
    "Bangkok_PO[\"text_original\"] = news\n",
    "Bangkok_PO[\"date\"] = time\n",
    "Bangkok_PO[\"year\"] = Bangkok_PO[\"date\"].dt.year\n",
    "Bangkok_PO[\"month\"] = Bangkok_PO[\"date\"].dt.month\n",
    "Bangkok_PO[\"outlet\"] = \"Bangkok Post\"\n",
    "Bangkok_PO[\"country\"] = \"Thailand\"\n",
    "Bangkok_PO[\"text_clean\"] = clean_text\n",
    "Bangkok_PO[\"South\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "791aa032",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/Sydney Morning Herald/**/*.rtf\", recursive = True):\n",
    "    with open(files, \"r\") as fi:\n",
    "        rtf = fi.read()    \n",
    "        text = rtf_to_text(rtf)\n",
    "        news.append(text)\n",
    "        names.append(files)\n",
    "    \n",
    "for n in news:\n",
    "    results = findtime(n, \"\\n\\w* \\d{1,2}, \\d{4}\", \"\\d{4} \\w*day\\n\")\n",
    "    \n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "    \n",
    "Sydney_MO = pd.DataFrame()\n",
    "Sydney_MO[\"filename\"] = names\n",
    "Sydney_MO[\"text_original\"] = news\n",
    "Sydney_MO[\"date\"] = time\n",
    "Sydney_MO[\"year\"] = Sydney_MO[\"date\"].dt.year\n",
    "Sydney_MO[\"month\"] = Sydney_MO[\"date\"].dt.month\n",
    "Sydney_MO[\"outlet\"] = \"The Sydney Morning Herald\"\n",
    "Sydney_MO[\"country\"] = \"Australia\"\n",
    "Sydney_MO[\"text_clean\"] = clean_text\n",
    "Sydney_MO[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "95dcfa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Australian/**/*.rtf\", recursive = True):\n",
    "    with open(files, \"r\") as fi:\n",
    "        rtf = fi.read()    \n",
    "        text = rtf_to_text(rtf)\n",
    "        news.append(text)\n",
    "        names.append(files)\n",
    "    \n",
    "for n in news:\n",
    "    results = findtime(n, \"\\n\\w* \\d{1,2}, \\d{4}\", \"\\d{4} \\w*day\\n\")\n",
    "    \n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "    \n",
    "The_Australian = pd.DataFrame()\n",
    "The_Australian[\"filename\"] = names\n",
    "The_Australian[\"text_original\"] = news\n",
    "The_Australian[\"date\"] = time\n",
    "The_Australian[\"year\"] = The_Australian[\"date\"].dt.year\n",
    "The_Australian[\"month\"] = The_Australian[\"date\"].dt.month\n",
    "The_Australian[\"outlet\"] = \"The Australian\"\n",
    "The_Australian[\"country\"] = \"Australia\"\n",
    "The_Australian[\"text_clean\"] = clean_text\n",
    "The_Australian[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "81700f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Guardian/**/*.rtf\", recursive = True):\n",
    "    with open(files, \"r\") as fi:\n",
    "        rtf = fi.read()    \n",
    "        text = rtf_to_text(rtf)\n",
    "        news.append(text)\n",
    "        names.append(files)\n",
    "    \n",
    "for n in news:\n",
    "    results = findtime(n, \"\\n\\w* \\d{1,2}, \\d{4}\", \"\\d{1,2}, \\d{4}\")\n",
    "    \n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "    \n",
    "The_Guardian = pd.DataFrame()\n",
    "The_Guardian[\"filename\"] = names\n",
    "The_Guardian[\"text_original\"] = news\n",
    "The_Guardian[\"date\"] = time\n",
    "The_Guardian[\"year\"] = The_Guardian[\"date\"].dt.year\n",
    "The_Guardian[\"month\"] = The_Guardian[\"date\"].dt.month\n",
    "The_Guardian[\"outlet\"] = \"Guardian\"\n",
    "The_Guardian[\"country\"] = \"UK\"\n",
    "The_Guardian[\"text_clean\"] = clean_text\n",
    "The_Guardian[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "cf0f41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The New York Times/**/*.rtf\", recursive = True):\n",
    "    with open(files, \"r\") as fi:\n",
    "        rtf = fi.read()    \n",
    "        text = rtf_to_text(rtf)\n",
    "        news.append(text)\n",
    "        names.append(files)\n",
    "    \n",
    "for n in news:\n",
    "    results = findtime(n, \"\\n\\w* \\d{1,2}, \\d{4}\", \"\\n\\w* \\d{1,2}, \\d{4}\")\n",
    "    \n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "    \n",
    "NY_Times = pd.DataFrame()\n",
    "NY_Times[\"filename\"] = names\n",
    "NY_Times[\"text_original\"] = news\n",
    "NY_Times[\"date\"] = time\n",
    "NY_Times[\"year\"] = NY_Times[\"date\"].dt.year\n",
    "NY_Times[\"month\"] = NY_Times[\"date\"].dt.month\n",
    "NY_Times[\"outlet\"] = \"The New York Times\"\n",
    "NY_Times[\"country\"] = \"USA\"\n",
    "NY_Times[\"text_clean\"] = clean_text\n",
    "NY_Times[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "9fe00679",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/The Press/**/*.rtf\", recursive = True):\n",
    "    with open(files, \"r\") as fi:\n",
    "        rtf = fi.read()    \n",
    "        text = rtf_to_text(rtf)\n",
    "        news.append(text)\n",
    "        names.append(files)\n",
    "    \n",
    "for n in news:\n",
    "    results = findtime(n, \"\\n\\w* \\d{1,2}, \\d{4}\", \"\\n\\w* \\d{1,2}, \\d{4}\")\n",
    "    \n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "    \n",
    "The_Press = pd.DataFrame()\n",
    "The_Press[\"filename\"] = names\n",
    "The_Press[\"text_original\"] = news\n",
    "The_Press[\"date\"] = time\n",
    "The_Press[\"year\"] = The_Press[\"date\"].dt.year\n",
    "The_Press[\"month\"] = The_Press[\"date\"].dt.month\n",
    "The_Press[\"outlet\"] = \"The_Press\"\n",
    "The_Press[\"country\"] = \"New Zealand\"\n",
    "The_Press[\"text_clean\"] = clean_text\n",
    "The_Press[\"South\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "04aec8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [Sunday_Times, Globe_Mail, Hindu, The_Nation, NZ_Herald, Star, Times, WPost, Times_IN, TO_Star,\n",
    "      Bangkok_PO, Sydney_MO, The_Australian, The_Guardian, NY_Times, The_Press]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "74c2ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "18bf1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "32c50f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34648"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "831708b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text_original</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>outlet</th>\n",
       "      <th>country</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>South</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>newsarticle/Sunday Times/Neutral 2022/Sunday T...</td>\n",
       "      <td>\\n   Insight\\nRevealing the Hex’ wildlife secr...</td>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday Times</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Insight Revealing the Hex’ wildlife secrets Bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newsarticle/Sunday Times/Neutral 2022/Sunday T...</td>\n",
       "      <td>\\n   Insight\\nWe’e seen the future and it floa...</td>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday Times</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Insight We’e seen the future and it floats Nad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newsarticle/Sunday Times/Neutral 2022/Sunday T...</td>\n",
       "      <td>\\n   News\\nHigher DIY power limit sparks corpo...</td>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday Times</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>News Higher DIY power limit sparks corporate i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newsarticle/Sunday Times/Neutral 2022/Sunday T...</td>\n",
       "      <td>\\n   News\\nFarming setbacks will keep food pri...</td>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday Times</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>News Farming setbacks will keep food prices hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newsarticle/Sunday Times/Neutral 2022/Sunday T...</td>\n",
       "      <td>\\n   Oped\\nMore brain, less bile needed in our...</td>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday Times</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Oped More brain, less bile needed in our polit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  newsarticle/Sunday Times/Neutral 2022/Sunday T...   \n",
       "1  newsarticle/Sunday Times/Neutral 2022/Sunday T...   \n",
       "2  newsarticle/Sunday Times/Neutral 2022/Sunday T...   \n",
       "3  newsarticle/Sunday Times/Neutral 2022/Sunday T...   \n",
       "4  newsarticle/Sunday Times/Neutral 2022/Sunday T...   \n",
       "\n",
       "                                       text_original       date  year  month  \\\n",
       "0  \\n   Insight\\nRevealing the Hex’ wildlife secr... 2022-01-09  2022      1   \n",
       "1  \\n   Insight\\nWe’e seen the future and it floa... 2022-01-09  2022      1   \n",
       "2  \\n   News\\nHigher DIY power limit sparks corpo... 2022-01-16  2022      1   \n",
       "3  \\n   News\\nFarming setbacks will keep food pri... 2022-01-16  2022      1   \n",
       "4  \\n   Oped\\nMore brain, less bile needed in our... 2022-01-30  2022      1   \n",
       "\n",
       "         outlet       country  \\\n",
       "0  Sunday Times  South Africa   \n",
       "1  Sunday Times  South Africa   \n",
       "2  Sunday Times  South Africa   \n",
       "3  Sunday Times  South Africa   \n",
       "4  Sunday Times  South Africa   \n",
       "\n",
       "                                          text_clean  South  \n",
       "0  Insight Revealing the Hex’ wildlife secrets Bo...      1  \n",
       "1  Insight We’e seen the future and it floats Nad...      1  \n",
       "2  News Higher DIY power limit sparks corporate i...      1  \n",
       "3  News Farming setbacks will keep food prices hi...      1  \n",
       "4  Oped More brain, less bile needed in our polit...      1  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce228609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ce4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6299f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9c30b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "time = []\n",
    "names = []\n",
    "\n",
    "for files in glob.glob(\"newsarticle/Sydney Morning Herald/**/*.rtf\", recursive = True):\n",
    "    with open(files, \"r\") as fi:\n",
    "        rtf = fi.read()    \n",
    "        text = rtf_to_text(rtf)\n",
    "        news.append(text)\n",
    "        names.append(files)\n",
    "    \n",
    "for n in news:\n",
    "    try:\n",
    "        results = findbetween(n, \"\\nSydney Morning Herald.*\\n\", \"\\n.*Edition.*\\n\\n\\nCopyright\")\n",
    "    except:\n",
    "        results = findbetween(n, \"\\nThe Sun Herald.*\\n\", \"\\n.*Edition.*\\n\\n\\nCopyright\")\n",
    "    \n",
    "    date = dateparser.parse(results, date_formats=['%d %B %Y'])\n",
    "    time.append(date)\n",
    "\n",
    "clean_text = [text.replace (\"\\n\", \"\") for text in news]\n",
    "clean_text = [\" \".join(text.split()) for text in news] \n",
    "    \n",
    "Sydney_MO = pd.DataFrame()\n",
    "Sydney_MO[\"filename\"] = names\n",
    "Sydney_MO[\"text_original\"] = news\n",
    "Sydney_MO[\"date\"] = time\n",
    "Sydney_MO[\"year\"] = Sydney_MO[\"date\"].dt.year\n",
    "Sydney_MO[\"month\"] = Sydney_MO[\"date\"].dt.month\n",
    "Sydney_MO[\"outlet\"] = \"The Sydney Morning Herald\"\n",
    "Sydney_MO[\"country\"] = \"Australia\"\n",
    "Sydney_MO[\"text_clean\"] = clean_text\n",
    "Sydney_MO[\"South\"] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
